---
title: "dbfinal"
output: html_document
---


```{r}
setwd("D:/Computer/Documents/Grad School/Spring22/Databases and Datamining/Final Project")

```


#loading the dataset 
```{r}
diabetes.data <-read.csv("PimaIndiansDiabetes.csv")
diabetes.data <- data.frame(diabetes.data)

#View(diabetes.data)
diabetes.data$Outcome <- as.factor(diabetes.data$Outcome)

```

#Question1
#Q1:Which variables are numeric and which are categorical? Explain why.(10pts)

#answer- 
#Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction and Age are all numeric variables given that these values come from numerical measurements of a patient. They are quantitative in nature. Also these variables have an almost infinite number of possibilities you can get for each one of them which makes them more of numeric variables. 

#Outcome is the target variable and its use is much different from the other variables. It is a categorical variable since whether a person has diabetes or not is assigned into two groups or categories- ie. 1~ yes the patient does have diabetes or 0~ no the patient doesnt have diabetes. This is qualitative in nature. 




#Q2: Use appropriate graphs to predict which of the variables (on their own) are most helpful in predicting the outcome? (20pts)
#For each variable draw an appropriate graph (boxplot for numerical values and barplot for categorical values). Explain your answer.

#answer-Given that all the variables are numerical asides from the outcome, I made a boxplot for each one below, displaying their relationship with the outcome. After looking at each, the Glucose would be the most helpful and accurate variable for predication given that there is less overlap between the median outomes and there are also less outliers that reside in the data. BMI,number of pregnanacies and age are also 2nd, 3rd and 4th best predictors of whether a patient will have diabtes. The less effective/bad predictors turns out to be Bloodpressure, skinthickness, insulin and DiabetesPedigreeFunction since would have higher rates of false predictions given that there is high overlaps in the medians and there are lots of outliers which would skew the data. 


```{r}
library(dplyr)
library(ggplot2)
```


```{r}
#box plot for Pregnancies
ggplot(data = diabetes.data) +
  geom_boxplot(mapping = aes(x = Pregnancies,y = Outcome, fill=as.factor(Outcome)))

```


```{r}
#box plot for Glucose

ggplot(data = diabetes.data) +
  geom_boxplot(mapping = aes(x = Glucose,y = Outcome, fill=as.factor(Outcome)))
```


```{r}
#box plot for Bloodpressure
ggplot(data = diabetes.data) +
  geom_boxplot(mapping = aes(x = BloodPressure,y = Outcome, fill=as.factor(Outcome)))
```

```{r}
#box plot for Skinthickness
ggplot(data = diabetes.data) +
  geom_boxplot(mapping = aes(x = SkinThickness,y = Outcome, fill=as.factor(Outcome)))
```


```{r}
#box plot for Insulin
ggplot(data = diabetes.data) +
  geom_boxplot(mapping = aes(x = Insulin,y = Outcome, fill=as.factor(Outcome)))
```


```{r}
#box plot for BMI
ggplot(data = diabetes.data) +
  geom_boxplot(mapping = aes(x = BMI,y = Outcome, fill=as.factor(Outcome)))
```

```{r}
#box plot for DiabetesPedigreeFunction
ggplot(data = diabetes.data) +
  geom_boxplot(mapping = aes(x = DiabetesPedigreeFunction,y = Outcome, fill=as.factor(Outcome)))
```

```{r}
#box plot for age 
ggplot(data = diabetes.data) +
  geom_boxplot(mapping = aes(x = Age,y = Outcome, fill=as.factor(Outcome)))
```
```{r}
varImpPlot(diabets.data)
```



#Q3-Are there any missing values? and how do we fix this?
#Notice that some of the values are missing and replaced with 0. For example a blood pressure of 0 doesnâ€™t make sense and it can have an impact on the models. So how do we identify which 0 reoresents the value 0 and which represents NA? Explain your answe

#Answer
#yes there are many missing values for Glucose, Bloodpressure, skinthickness, insulin, and BMI. This is true since all the variables have some values that are 0 which does not make logical sense on a biological level. The variables DiabetesPedigreeFunction and Age have no missing values. It is hard to tell if the pregnancy variable has missing values given that it is very possible to have a patient that has never been pregnant. Consequenty, I am going to leave the values for pregnancy as is so that I do not alter or skew that data. 

#Since there are many instances of missing values removing/deleting rows that have that have missing values wouldnt be optimal since is the case removing these patterns the number of patterns in your dataset will drastically decrease and the training phase will not be adequate. Instead I will replace the missing variable with the means.


```{r}
#updating the dataframe so that the 0 values are replaced with the mean for the appropriate variables

#creating a new dataframe to manipulate
newdiabetes.data<-data.frame(diabetes.data)

#turning the values that are 0 into NA's so that I can calculate the mean of the real values (not including the 0s)
is.na(newdiabetes.data[,c(2:6)]) <- newdiabetes.data[,c(2:6)]==0

#calculating the variable means of the data not including the 0s in the dataset
colMeans(newdiabetes.data[,c(2:6)], na.rm=TRUE) 

```

```{r}
#turning all the 0s from the original dataframe to the correct means for the variables

diabetes.data["Glucose"][diabetes.data["Glucose"] == 0] <-  121.31373
diabetes.data["BloodPressure"][diabetes.data["BloodPressure"] == 0] <-  72.20755
diabetes.data["SkinThickness"][diabetes.data["SkinThickness"] == 0] <-   29.10805
diabetes.data["Insulin"][diabetes.data["Insulin"] == 0] <- 153.78324 
diabetes.data["BMI"][diabetes.data["BMI"] == 0] <- 32.29530


#View(diabetes.data)

#diabetes$Outcome =as.factor(diabetes$Outcome)
```



#Q4-Building the model 
# I am going to use Neural networks. Neural Networks have the ability to learn by themselves and produce the output that is not limited to the input provided to them. Given that there were many missing datapoints to begin with, neural networks is a good choice since even with missing information, the network can detect the fault and still produce the output. Neural networks also use hidden layers which may be beneficial since they allow us to capture various minute details which results in discovering various relationships between different inputs producing a more accurate output.

#Since the values vary broadly for each variabe, I am going to first nromalize/scale the data to a range that is 0-1. This is also a must when using neural network algorithms since it will allow training the model to be much faster and accurate. 

#after scaling the data, I will randomly select 70% of the data for the training set and leave out 30% of the data for the test set. 

#when running the neural network model, I will use different numbers of hidden layers to see which produces the best result. 



```{r}
#download the neural networks package 
#install.packages("neuralnet")
library(neuralnet)
```

```{r}
#creating max and min values for scaling
maxs= apply(diabetes.data[,1:8],2, max)
mins= apply(diabetes.data[,1:8],2, min)
```


```{r}
#scaling the data using the max and min values. 

scale.data= as.data.frame(scale(diabetes.data[,1:8], 
                                center=mins, 
                                scale=maxs-mins))


Outcome = as.numeric(diabetes.data$Outcome)-1

#adding the outcome values to the scaled dataframe
Scaled.data.df =cbind(scale.data, Outcome)

View(Scaled.data.df)
```


```{r}
#SAMPLING
#setting 70% of the data to training_set

nntrainingdata <-sample(nrow(Scaled.data.df), floor(nrow(Scaled.data.df)*0.7))

nntraining_set <- Scaled.data.df[nntrainingdata,]

#setting all the values not included in the training_set over to the test_set (30% of data)
nntest_set<- Scaled.data.df[-nntrainingdata,]

```

```{r}
table(nntraining_set[, "Outcome"])
```


```{r}
table(nntest_set[, "Outcome"])
```


```{r}
#overall I used a neural network with 2 hidden layers. This produed the best results averging > 80% accuracy.
data.nn<- neuralnet(Outcome~., data=nntraining_set, hidden=2, rep=1, linear.output = F)

```

```{r}
plot(data.nn)
```


```{r}
library(AUC)
data.nn.results =compute(data.nn, nntest_set[,1:8])
data.nn.roc= roc(data.nn.results$net.result, as.factor(nntest_set$Outcome))
auc(data.nn.roc)
```


```{r}
plot(data.nn.roc, main=paste(" AUC = ", auc(data.nn.roc), sep= " "))
```



